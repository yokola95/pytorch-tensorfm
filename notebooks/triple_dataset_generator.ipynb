{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "soI3P811MsVI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fjBebcl_NENK"
   },
   "outputs": [],
   "source": [
    "# configuration\n",
    "num_fields = 8                # number of fields in the dataset\n",
    "num_rows = 1000000            # the number of rows to generate in the dataset\n",
    "mean_num_features = 20        # average number of features in each field\n",
    "n_subsets = num_fields ** 2   # number of field subsets to consider for interactions\n",
    "nonzero_pct = 0.8             # mean percentage of non-zero features per field. We assume that 'zero' is some special value, such as \"Missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, validation rel. sizes and indices inside the single common dataframe\n",
    "train_size = 0.8\n",
    "test_size = 0.1\n",
    "validation_size = 0.1\n",
    "\n",
    "train_st = 0\n",
    "train_end = int(train_size * num_rows)\n",
    "test_st = (num_rows-int(test_size * num_rows))\n",
    "test_end = num_rows\n",
    "validation_st = (num_rows-int((validation_size + test_size) * num_rows))\n",
    "validation_end = test_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wsLl1XbTM1tu"
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGc4PtqBPq2f",
    "outputId": "0ad02584-60fb-4ed9-be04-69373332728f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48, 47, 48, 7, 3, 30, 29, 62]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate number of features per field\n",
    "num_features = [\n",
    "    1 + rng.geometric(1. / mean_num_features) for _ in range(num_fields)\n",
    "]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t0q1viyZNMOc"
   },
   "outputs": [],
   "source": [
    "# generate fields\n",
    "cols = []\n",
    "for n in num_features:\n",
    "  features = rng.binomial(1, nonzero_pct, size=num_rows)\n",
    "  if n > 2:\n",
    "    half = n // 2\n",
    "    rest = n - half\n",
    "    features *= rng.integers(0, half, size=num_rows) + rng.integers(1, rest + 1, size=num_rows)\n",
    "  cols.append(features.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "v8dZq0nRQnlP"
   },
   "outputs": [],
   "source": [
    "# choose field subsets for interaction. This will affect the labels\n",
    "subsets = []\n",
    "for i in range(n_subsets):\n",
    "  size = rng.integers(2, 4)\n",
    "  subset = rng.choice(num_fields, size=size, replace=False)\n",
    "  subsets.append(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LE1Vj3KelJqk"
   },
   "outputs": [],
   "source": [
    "# generate feature effects per field\n",
    "feature_effects = []\n",
    "for n in num_features:\n",
    "  feature_effects.append(rng.standard_exponential(size=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "V4JkKdrTWyCV"
   },
   "outputs": [],
   "source": [
    "# generate indicators of positiveness of the cumulative effect of each subset.\n",
    "subset_thresholding = []\n",
    "for subset in subsets:\n",
    "  effect_agg = np.zeros(num_rows)\n",
    "  for field in subset:\n",
    "    effect_agg = np.maximum(effect_agg, feature_effects[field][cols[field]])\n",
    "  subset_thresholding.append(np.asarray(effect_agg > 2, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K93IsNF6W0_e"
   },
   "outputs": [],
   "source": [
    "# labels are randomly generated\n",
    "prob = np.clip(np.column_stack(subset_thresholding).mean(axis=-1), a_min=1e-5, a_max=1-1e-5)\n",
    "label = rng.binomial(1, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j90-7jYNj-CS",
    "outputId": "9c932059-82b5-43ec-f503-e84608e342b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19604313, 0.195608)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prob), np.mean(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xo7NWoH5kq6y",
    "outputId": "06bb42de-69d8-400b-c4fb-3b6d8612e2b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4942532035777099"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the naive loss of a predictor that predicts the average CTR for all events\n",
    "naive_loss = -np.mean(label) * np.log(np.mean(label)) - (1 - np.mean(label)) * np.log(1 - np.mean(label))\n",
    "naive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jafmgwsAgxef",
    "outputId": "a3e7df9f-653a-460f-8038-3a72047dbd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32664252463672233"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best achievable loss is the loss of an oracle that knows the ``true''\n",
    "# probability of each event. Should be significantly lower than the naive loss,\n",
    "# so that there is something to actually learn.\n",
    "optimal_loss = -label * np.log(prob) - (1 - label) * np.log(1 - prob)\n",
    "optimal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5CR6vfnqYHUj"
   },
   "outputs": [],
   "source": [
    "shift = 0\n",
    "for i, n in enumerate(num_features):\n",
    "  cols[i] = cols[i] + shift\n",
    "  shift += n\n",
    "\n",
    "col_names = [f\"f{i}\" for i in range(num_fields)]\n",
    "df = pd.DataFrame(np.column_stack(cols), columns=col_names)\n",
    "df[\"label\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "RLh4Bpmjcau0",
    "outputId": "c9720c61-451f-4949-af82-77d343664b0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>69</td>\n",
       "      <td>133</td>\n",
       "      <td>147</td>\n",
       "      <td>151</td>\n",
       "      <td>168</td>\n",
       "      <td>183</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>144</td>\n",
       "      <td>151</td>\n",
       "      <td>167</td>\n",
       "      <td>200</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>121</td>\n",
       "      <td>147</td>\n",
       "      <td>152</td>\n",
       "      <td>167</td>\n",
       "      <td>186</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>182</td>\n",
       "      <td>190</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>95</td>\n",
       "      <td>143</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>124</td>\n",
       "      <td>148</td>\n",
       "      <td>152</td>\n",
       "      <td>180</td>\n",
       "      <td>197</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>12</td>\n",
       "      <td>65</td>\n",
       "      <td>122</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>167</td>\n",
       "      <td>188</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>29</td>\n",
       "      <td>48</td>\n",
       "      <td>124</td>\n",
       "      <td>148</td>\n",
       "      <td>152</td>\n",
       "      <td>170</td>\n",
       "      <td>202</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>21</td>\n",
       "      <td>83</td>\n",
       "      <td>120</td>\n",
       "      <td>148</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>192</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>111</td>\n",
       "      <td>147</td>\n",
       "      <td>152</td>\n",
       "      <td>180</td>\n",
       "      <td>183</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0  f1   f2   f3   f4   f5   f6   f7  label\n",
       "0       34  69  133  147  151  168  183  224      0\n",
       "1       41  80  120  144  151  167  200  245      0\n",
       "2       13  48  121  147  152  167  186  227      0\n",
       "3        0  92   95  146  152  182  190  240      0\n",
       "4       25  73   95  143  152  153  200  260      0\n",
       "...     ..  ..  ...  ...  ...  ...  ...  ...    ...\n",
       "999995   5  64  124  148  152  180  197  219      0\n",
       "999996  12  65  122  146  150  167  188  247      0\n",
       "999997  29  48  124  148  152  170  202  212      1\n",
       "999998  21  83  120  148  150  153  192  265      0\n",
       "999999   0  71  111  147  152  180  183  263      0\n",
       "\n",
       "[1000000 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ni3zXaT-cbL7"
   },
   "outputs": [],
   "source": [
    "#df.to_csv(\"dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "     f0  f1   f2   f3   f4   f5   f6   f7  label\n",
      "661  29  78  105  148  151  171  197  273      1\n",
      "661\n"
     ]
    }
   ],
   "source": [
    "# Find the overall maximum value in the DataFrame\n",
    "overall_max = df.max().max()\n",
    "print(overall_max)\n",
    "\n",
    "# Find the row containing the overall maximum value\n",
    "max_row = df[df.eq(overall_max).any(axis=1)].head(1)\n",
    "print(max_row)\n",
    "print(max_row.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[train_st:train_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if max_row.index[0] >= train_end:\n",
    "    train_df = pd.concat([df[train_st:train_end],max_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/viderman/persistent_drive/pytorch-tensorfm/data/test-datasets/triple-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(f\"{path}/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "w44Sw2ZakYsl"
   },
   "outputs": [],
   "source": [
    "df[test_st:test_end].to_csv(f\"{path}/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[validation_st:validation_end].to_csv(f\"{path}/validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_KSbq1dftgR"
   },
   "source": [
    "# Sanity - verify that logistic regression's log-loss is between the naive and the optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "w44Sw2ZakYsl"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "o8TXEs8MeA4y"
   },
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (OneHotEncoder(), col_names),\n",
    "        remainder=\"passthrough\"\n",
    "    ),\n",
    "    LogisticRegressionCV()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gngwhRUsfAIz"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rFvpgCFredyA"
   },
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(train.drop(columns=[\"label\"]), train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRqqeEU2eyHt",
    "outputId": "ef8e097b-af03-42a5-dfa0-f871aa667dfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35988299246501126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test[\"label\"], pipeline.predict_proba(test.drop(columns=[\"label\"]))[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
